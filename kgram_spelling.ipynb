{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aafb17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import List, Set, Dict, Tuple\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9']+\", \" \", text)\n",
    "    return [t for t in text.split() if t]\n",
    "\n",
    "def kgrams(term: str, k: int = 2, use_boundaries: bool = False) -> Set[str]:\n",
    "    t = ('^' + term + '$') if use_boundaries else term\n",
    "    if len(t) < k:\n",
    "        return {t}\n",
    "    return {t[i:i+k] for i in range(len(t)-k+1)}\n",
    "\n",
    "def build_kgram_index_from_docs(documents: List[str], k: int = 2, use_boundaries: bool = False) -> Tuple[Dict[str, Set[str]], Set[str]]:\n",
    "    vocab = set()\n",
    "    for doc in documents:\n",
    "        vocab.update(tokenize(doc))\n",
    "    index = defaultdict(set)\n",
    "    for term in vocab:\n",
    "        for kg in kgrams(term, k, use_boundaries):\n",
    "            index[kg].add(term)\n",
    "    return dict(index), vocab\n",
    "\n",
    "def generate_candidates_from_index(query_word: str, index: Dict[str, Set[str]], k: int = 2, use_boundaries: bool = False, max_candidates: int = 1000) -> Set[str]:\n",
    "    q_k = kgrams(query_word, k, use_boundaries)\n",
    "    candidates = set()\n",
    "    for kg in q_k:\n",
    "        candidates.update(index.get(kg, ()))\n",
    "        if len(candidates) >= max_candidates:\n",
    "            break\n",
    "    candidates.discard(query_word)\n",
    "    return candidates\n",
    "\n",
    "def jaccard_score(q_k: Set[str], c_k: Set[str]) -> float:\n",
    "    inter = q_k & c_k\n",
    "    union = q_k | c_k\n",
    "    return len(inter) / len(union) if union else 0.0\n",
    "\n",
    "def correct_query(documents: List[str], query: str, k: int = 2, use_boundaries: bool = False, jaccard_threshold: float = 0.1, top_k_candidates: int = 1) -> Tuple[str, Dict[str, List[Tuple[str,float]]]]:\n",
    "    index, vocab = build_kgram_index_from_docs(documents, k, use_boundaries)\n",
    "    tokens = tokenize(query)\n",
    "    corrected = []\n",
    "    diagnostics = {}\n",
    "    for tok in tokens:\n",
    "        if tok in vocab:\n",
    "            corrected.append(tok)\n",
    "            diagnostics[tok] = [(tok, 1.0)]\n",
    "            continue\n",
    "        q_k = kgrams(tok, k, use_boundaries)\n",
    "        candidates = generate_candidates_from_index(tok, index, k, use_boundaries)\n",
    "        scored = []\n",
    "        for cand in candidates:\n",
    "            c_k = kgrams(cand, k, use_boundaries)\n",
    "            j = jaccard_score(q_k, c_k)\n",
    "            if j >= jaccard_threshold:\n",
    "                scored.append((cand, j))\n",
    "        scored.sort(key=lambda x: (-x[1], len(x[0]), x[0]))\n",
    "        top = scored[:top_k_candidates]\n",
    "        diagnostics[tok] = top\n",
    "        corrected.append(top[0][0] if top else tok)\n",
    "    return \" \".join(corrected), diagnostics\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    docs = [\n",
    "        \"The cat sat on the mat\",\n",
    "        \"The dog barked at the cat\",\n",
    "        \"The quick brown fox jumped over the lazy dog\",\n",
    "        \"Cats and dogs are common pets\",\n",
    "        \"I love my dog and my cat\",\n",
    "        \"Python is a popular programming language\",\n",
    "        \"Machine learning is a subset of artificial intelligence\",\n",
    "        \"I ate an apple every day\",\n",
    "        \"She likes to eat a pea and an ape sometimes\",\n",
    "        \"He bought an applet and an apple\",\n",
    "        \"We visited the chapel near the apple orchard\",\n",
    "        \"They drank a frappe at the cafe\"\n",
    "    ]\n",
    "    queries = [\n",
    "        \"I ate an appe every day\",\n",
    "        \"She saw an aple and an ape\",\n",
    "        \"He visited the chapell nearby\",\n",
    "        \"I like machne learning\",\n",
    "        \"I want a frape drink\"\n",
    "    ]\n",
    "    for q in queries:\n",
    "        corrected, diag = correct_query(docs, q, k=2, use_boundaries=False, jaccard_threshold=0.2, top_k_candidates=1)\n",
    "        print(\"Query:   \", q)\n",
    "        print(\"Corrected:\", corrected)\n",
    "        print(\"Candidates per token:\")\n",
    "        for tok, candlist in diag.items():\n",
    "            print(\"  \", tok, \"->\", candlist)\n",
    "        print(\"-\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
