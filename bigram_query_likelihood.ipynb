{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"A quick brown dog barks loudly.\",\n",
    "    \"The lazy dog sleeps in the sun.\",\n",
    "    \"A brown fox runs fast.\",\n",
    "    \"The sun is bright today.\"\n",
    "]\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "preprocessed_documents = []\n",
    "for doc in documents:\n",
    "    tokens = word_tokenize(doc.lower())\n",
    "    tokens = [t for t in tokens if t.isalpha() and t not in stop_words]\n",
    "    preprocessed_documents.append(tokens)\n",
    "\n",
    "def get_unigram_counts(doc):\n",
    "    counts = Counter(doc)\n",
    "    total = sum(counts.values())\n",
    "    return counts, total\n",
    "\n",
    "def get_bigram_counts(doc):\n",
    "    bigrams = list(zip([\"<s>\"] + doc, doc + [\"</s>\"]))\n",
    "    counts = Counter(bigrams)\n",
    "    total = sum(counts.values())\n",
    "    return counts, total\n",
    "\n",
    "def unigram_prob(word, unigram_counts, total, alpha=1):\n",
    "    vocab_size = len(unigram_counts)\n",
    "    return (unigram_counts.get(word, 0) + alpha) / (total + alpha * vocab_size)\n",
    "\n",
    "def bigram_prob(w1, w2, bigram_counts, unigram_counts, alpha=1):\n",
    "    vocab_size = len(unigram_counts)\n",
    "    return (bigram_counts.get((w1, w2), 0) + alpha) / (unigram_counts.get(w1, 0) + alpha * vocab_size)\n",
    "\n",
    "def query_log_likelihood_unigram(query, docs):\n",
    "    results = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        unigram_counts, total = get_unigram_counts(doc)\n",
    "        log_prob = 0\n",
    "        for w in query:\n",
    "            log_prob += math.log(unigram_prob(w, unigram_counts, total))\n",
    "        results.append((i, log_prob))\n",
    "    return results\n",
    "\n",
    "def query_log_likelihood_bigram(query, docs):\n",
    "    results = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        unigram_counts, total_unigram = get_unigram_counts(doc)\n",
    "        bigram_counts, total_bigram = get_bigram_counts(doc)\n",
    "        log_prob = 0\n",
    "        prev_word = \"<s>\"\n",
    "        for w in query + [\"</s>\"]:\n",
    "            log_prob += math.log(bigram_prob(prev_word, w, bigram_counts, unigram_counts))\n",
    "            prev_word = w\n",
    "        results.append((i, log_prob))\n",
    "    return results\n",
    "\n",
    "query = [\"sun\", \"bright\"]\n",
    "\n",
    "uni_scores = query_log_likelihood_unigram(query, preprocessed_documents)\n",
    "bi_scores = query_log_likelihood_bigram(query, preprocessed_documents)\n",
    "\n",
    "print(\"Unigram Log-Likelihoods:\")\n",
    "for i, score in uni_scores:\n",
    "    print(f\"Doc {i+1}: {score:.4f}\")\n",
    "\n",
    "print(\"\\nBigram Log-Likelihoods:\")\n",
    "for i, score in bi_scores:\n",
    "    print(f\"Doc {i+1}: {score:.4f}\")\n",
    "\n",
    "best_uni = max(uni_scores, key=lambda x: x[1])\n",
    "best_bi = max(bi_scores, key=lambda x: x[1])\n",
    "\n",
    "print(f\"\\nMost likely document (Unigram): Doc {best_uni[0]+1}\")\n",
    "print(f\"Most likely document (Bigram): Doc {best_bi[0]+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-mQL0Ebl_vh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
